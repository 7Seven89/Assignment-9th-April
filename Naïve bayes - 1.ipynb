{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817657d7-6b26-4d4c-88bf-f95288d28357",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?\n",
    "\n",
    "### Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "### Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "### Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "| Class | X1=1 | X1=2 | X1=3 | X2=1 | X2=2 | X2=3 | X2=4 |\n",
    "|-------|------|------|------|------|------|------|------|\n",
    "| A     | 3    | 3    | 4    | 4    | 3    | 3    | 3    |\n",
    "| B     | 2    | 2    | 1    | 2    | 2    | 2    | 3    |\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d769ef6-5e20-4ea2-8cb9-a9218b957fe0",
   "metadata": {},
   "source": [
    "# Q1. What is Bayes' theorem?\n",
    "\n",
    "Bayes' theorem is a mathematical formula used for updating the probability of a hypothesis based on new evidence. It provides a way to revise the predictions or beliefs about the world in light of new data, particularly useful in probabilistic reasoning and machine learning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257f422-5af0-4f0f-a3b5-5ce7d231822b",
   "metadata": {},
   "source": [
    "# Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "Bayes' theorem is expressed as:\n",
    "\n",
    "\\[\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the **posterior probability**: the probability of hypothesis \\( A \\) given the data \\( B \\).\n",
    "- \\( P(B|A) \\) is the **likelihood**: the probability of the data \\( B \\) given that hypothesis \\( A \\) is true.\n",
    "- \\( P(A) \\) is the **prior probability**: the initial belief about the hypothesis before seeing the data.\n",
    "- \\( P(B) \\) is the **evidence**: the total probability of the data across all possible hypotheses.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c9a75-0de5-41a6-aa0d-027deb3e53dd",
   "metadata": {},
   "source": [
    "# Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Bayes' theorem is widely used in:\n",
    "1. **Machine Learning**: In algorithms like Naive Bayes classifiers, it helps calculate the posterior probabilities of classes given observed data.\n",
    "2. **Medical Diagnostics**: Used to revise the probability of a disease based on new test results.\n",
    "3. **Spam Filtering**: To determine the probability that an email is spam based on the presence of certain words.\n",
    "4. **Decision Making**: In decision theory and artificial intelligence, it helps in updating probabilities as more information becomes available.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c1f8a-e2f5-49bd-b735-9f00f1dd4958",
   "metadata": {},
   "source": [
    "# Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Bayes' theorem is essentially a formalization of **conditional probability**. Conditional probability is the probability of an event occurring given that another event has already occurred. In Bayes' theorem:\n",
    "- \\( P(A|B) \\) represents the conditional probability of \\( A \\) given \\( B \\).\n",
    "- Bayes' theorem reverses the conditional probability and provides a way to update our beliefs based on new evidence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db7948-54b1-4bf3-9566-ef9159cafb5e",
   "metadata": {},
   "source": [
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "There are three main types of Naive Bayes classifiers:\n",
    "1. **Gaussian Naive Bayes**: Assumes that the features follow a normal (Gaussian) distribution. Itâ€™s ideal for problems where features are continuous and normally distributed.\n",
    "2. **Multinomial Naive Bayes**: Suitable for problems where the features are discrete counts (e.g., text classification problems where word counts are used as features).\n",
    "3. **Bernoulli Naive Bayes**: Assumes binary features (e.g., presence/absence of a feature), making it ideal for binary classification problems with binary features.\n",
    "\n",
    "The choice of classifier depends on the nature of the features in the dataset (continuous vs. discrete, binary vs. multinomial).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d903c7-a30c-4856-ac53-8ce8800056b6",
   "metadata": {},
   "source": [
    "# Q6. Assignment:\n",
    "\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "| Class | X1=1 | X1=2 | X1=3 | X2=1 | X2=2 | X2=3 | X2=4 |\n",
    "|-------|------|------|------|------|------|------|------|\n",
    "| A     | 3    | 3    | 4    | 4    | 3    | 3    | 3    |\n",
    "| B     | 2    | 2    | 1    | 2    | 2    | 2    | 3    |\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?\n",
    "\n",
    "To solve this:\n",
    "1. **Calculate the likelihoods** for both classes \\( P(X1=3|A), P(X2=4|A), P(X1=3|B), P(X2=4|B) \\).\n",
    "   \\[\n",
    "   P(X1=3|A) = \\frac{\\text{count of } X1=3 \\text{ in class A}}{\\text{total count of class A features}} = \\frac{4}{13}\n",
    "   \\]\n",
    "   \\[\n",
    "   P(X2=4|A) = \\frac{3}{13}, \\quad P(X1=3|B) = \\frac{1}{7}, \\quad P(X2=4|B) = \\frac{3}{7}\n",
    "   \\]\n",
    "\n",
    "2. **Calculate the posterior probability** for each class using Bayes' theorem:\n",
    "   \\[\n",
    "   P(A|X1=3, X2=4) \\propto P(X1=3|A) \\cdot P(X2=4|A) \\cdot P(A)\n",
    "   \\]\n",
    "   \\[\n",
    "   P(B|X1=3, X2=4) \\propto P(X1=3|B) \\cdot P(X2=4|B) \\cdot P(B)\n",
    "   \\]\n",
    "\n",
    "   Since the priors \\( P(A) \\) and \\( P(B) \\) are equal, the comparison will depend on the likelihoods.\n",
    "\n",
    "3. **Compare** the posterior probabilities and predict the class with the highest probability.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
